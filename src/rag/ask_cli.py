# RAG system for educational support consultations
import os
import re
import sys
import time
from pathlib import Path

from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS

def load_api_keys():
    """Load API keys from configuration file"""
    env_file = Path("api_keys.env")
    if env_file.exists():
        for line in env_file.read_text().splitlines():
            if line.strip() and not line.startswith("#"):
                key, value = line.split("=", 1)
                os.environ[key.strip()] = value.strip()

load_api_keys()

PERSIST = "rag_index/faiss_e5"

# Get user query
query = " ".join(sys.argv[1:]).strip() or \
    "Å½iak s ADHD nevydrÅ¾Ã­ 10 minÃºt sÃºstredenia â€“ Äo odporÃºÄate na Ãºrovni 1â€“2?"

# Initialize vector database
EMBED_MODEL = os.environ.get("EMBED_MODEL", "intfloat/multilingual-e5-small")
embedder = HuggingFaceEmbeddings(
    model_name=EMBED_MODEL,
    encode_kwargs={"normalize_embeddings": True},
)
vs = FAISS.load_local(PERSIST, embeddings=embedder, allow_dangerous_deserialization=True)

# Search for relevant documents
docs_all = vs.similarity_search(query, k=20)

# Extended search by keywords
keywords = []
if "pozornosÅ¥" in query.lower() or "sÃºstredenie" in query.lower():
    keywords.extend(["pozornosÅ¥", "sÃºstredenie", "ADHD", "organizÃ¡cia", "Äas"])
if "matematika" in query.lower():
    keywords.extend(["matematika", "matematickÃ©", "poÄÃ­tanie", "Ãºlohy"])
if "hodina" in query.lower():
    keywords.extend(["hodina", "vyuÄovanie", "organizÃ¡cia", "ÄasovÃ©"])

for keyword in keywords[:3]:
    try:
        keyword_docs = vs.similarity_search(keyword, k=5)
        docs_all.extend(keyword_docs)
    except:
        continue

# Remove duplicates
seen_ids = set()
unique_docs = []
for doc in docs_all:
    doc_id = doc.metadata.get("source_file", "") + str(doc.page_content[:100])
    if doc_id not in seen_ids:
        seen_ids.add(doc_id)
        unique_docs.append(doc)

docs_all = unique_docs

# Filter by support levels
def level_ok(meta: dict) -> bool:
    lv = (meta or {}).get("levels", "")
    if not lv:
        return True
    return any(x in lv for x in ["1", "2"])

docs_filtered = [d for d in docs_all if level_ok(d.metadata)]
docs = docs_filtered[:12] if docs_filtered else docs_all[:12]

# Prepare context for LLM
def compact(txt: str) -> str:
    return re.sub(r"\s+", " ", txt).strip()

context_blocks = []
sources_info = []
for i, d in enumerate(docs, 1):
    title = d.metadata.get("title", "") or ""
    url = d.metadata.get("url", "") or ""
    snippet = compact(d.page_content)[:1000]
    context_blocks.append(f"[{i}] {title}\n---\n{snippet}")
    sources_info.append({"num": i, "title": title, "url": url})

context = "\n\n".join(context_blocks)

# System prompt for LLM
system_prompt = """Si expertnÃ½ asistent Å¡peciÃ¡lneho pedagÃ³ga na Slovensku s hlbokÃ½mi znalosÅ¥ami o podpornÃ½ch opatreniach a inkluzÃ­vnom vzdelÃ¡vanÃ­.

Tvoja Ãºloha: PoskytovaÅ¥ konkrÃ©tne, praktickÃ© a realizovateÄ¾nÃ© rieÅ¡enia na zÃ¡klade oficiÃ¡lnych dokumentov.

ANALYTICKÃ PRÃSTUP:
1. Najprv analyzuj problÃ©m v otÃ¡zke
2. Identifikuj kÄ¾ÃºÄovÃ© potreby Å¾iaka/dieÅ¥aÅ¥a
3. Vyber najrelevantnejÅ¡ie opatrenia z dokumentov
4. Navrhni konkrÃ©tne kroky pre realizÃ¡ciu

FORMÃT ODPOVEDE:
## ğŸ¯ AnalÃ½za problÃ©mu
- StruÄnÃ½ popis identifikovanÃ©ho problÃ©mu
- KÄ¾ÃºÄovÃ© potreby Å¾iaka

## ğŸ“‹ KonkrÃ©tne opatrenia na zajtra
### Pre uÄiteÄ¾a:
- [UÄiteÄ¾] KonkrÃ©tna ÄinnosÅ¥ s presnÃ½m popisom
- [UÄiteÄ¾] ÄalÅ¡ia ÄinnosÅ¥...

### Pre asistenta pedagÃ³ga:
- [Asistent] Å pecifickÃ¡ Ãºloha s detajlami
- [Asistent] ÄalÅ¡ia Ãºloha...

### Pre Å¡kolu/vedenie:
- [Å kola] OrganizaÄnÃ© opatrenie
- [Å kola] ÄalÅ¡ie opatrenie...

## âš–ï¸ Ãšpravy hodnotenia (ak relevantnÃ©)
- KonkrÃ©tne spÃ´soby hodnotenia
- AdaptÃ¡cie pre Å¾iaka

PRAVIDLÃ:
- BuÄ maximÃ¡lne konkrÃ©tny a praktickÃ½
- Odpovedaj VÃLUÄŒNE na zÃ¡klade poskytnutÃ½ch dokumentov
- Ak informÃ¡cie chÃ½bajÃº, napÃ­Å¡ "PotrebnÃ© doplniÅ¥ z odbornÃ½ch zdrojov"
- PouÅ¾Ã­vaj slovenskÃ½ jazyk
- Zameraj sa na realizovateÄ¾nÃ© rieÅ¡enia
- NEUVÃDZAJ zdroje v Ñ‚ĞµĞºÑÑ‚Ñ– - budÃº pridanÃ© automaticky"""

user_prompt = f"""OtÃ¡zka: {query}

Kontekst:
{context}
"""

# Offline mode for cases without API
def offline_reply(docs_list):
    print("## ğŸ¯ AnalÃ½za problÃ©mu")
    print("- IdentifikovanÃ½ problÃ©m: Potreba podpory pre Å¾iaka s problÃ©mami sÃºstredenia")
    print("- KÄ¾ÃºÄovÃ© potreby: OrganizÃ¡cia hodiny, ÄasovÃ© signÃ¡ly, rozdelenie Ãºloh")
    print()
    
    print("## ğŸ“‹ KonkrÃ©tne opatrenia na zajtra")
    print("### Pre uÄiteÄ¾a:")
    
    teacher_actions = []
    assistant_actions = []
    school_actions = []
    
    for d in docs_list:
        content = d.page_content.lower()
        sentences = re.split(r'(?<=[.!?])\s+', d.page_content)
        
        for sentence in sentences:
            sentence = sentence.strip()
            if len(sentence) < 30 or len(sentence) > 400:
                continue
                
            if any(word in sentence.lower() for word in ['uÄiteÄ¾', 'pedagÃ³g', 'vyuÄovanie', 'hodina', 'trieda', 'organizÃ¡cia']):
                if any(action in sentence.lower() for action in ['upraviÅ¥', 'zmeniÅ¥', 'pouÅ¾iÅ¥', 'zabezpeÄiÅ¥', 'poskytnÃºÅ¥', 'rozdeliÅ¥', 'Äas']):
                    teacher_actions.append(f"- [UÄiteÄ¾] {sentence.strip()}")
            
            elif any(word in sentence.lower() for word in ['asistent', 'pedagogickÃ½ asistent', 'podpora']):
                if any(action in sentence.lower() for action in ['pomÃ´cÅ¥', 'podporiÅ¥', 'asistovaÅ¥', 'spolupracovaÅ¥']):
                    assistant_actions.append(f"- [Asistent] {sentence.strip()}")
            
            elif any(word in sentence.lower() for word in ['Å¡kola', 'vedenie', 'riaditeÄ¾', 'zariadenie']):
                if any(action in sentence.lower() for action in ['zabezpeÄiÅ¥', 'poskytnÃºÅ¥', 'upraviÅ¥', 'zmeniÅ¥']):
                    school_actions.append(f"- [Å kola] {sentence.strip()}")
    
    all_actions = teacher_actions[:4] + assistant_actions[:2] + school_actions[:2]
    
    if all_actions:
        for action in all_actions[:6]:
            print(action)
    else:
        print("- [UÄiteÄ¾] RozdeliÅ¥ hodinu na kratÅ¡ie ÄasovÃ© Ãºseky (10-15 min)")
        print("- [UÄiteÄ¾] PouÅ¾iÅ¥ vizuÃ¡lne signÃ¡ly pre zmeny aktivÃ­t")
        print("- [UÄiteÄ¾] PoskytnÃºÅ¥ ÄastÃ© prestÃ¡vky na pohyb")
        print("- [Asistent] PomÃ´cÅ¥ Å¾iakovi s organizÃ¡ciou pracovnÃ©ho miesta")
        print("- [Å kola] ZabezpeÄiÅ¥ vhodnÃ© prostredie pre sÃºstredenie")
    
    print("\n## ğŸ“š Zdroje")
    for i, d in enumerate(docs_list, 1):
        title = d.metadata.get("title", "")
        url = d.metadata.get("url", "")
        if url:
            print(f"[{i}] {title} â€” {url}")
        else:
            print(f"[{i}] {title}")

# Main execution block with LLM
ANTHROPIC = os.environ.get("ANTHROPIC_API_KEY", "").strip()
OPENAI = os.environ.get("OPENAI_API_KEY", "").strip()

if ANTHROPIC:
    try:
        from langchain_anthropic import ChatAnthropic
        model_name = os.environ.get("ANTHROPIC_MODEL", "claude-3-5-sonnet-20240620")
        llm = ChatAnthropic(model=model_name, temperature=0, max_tokens=600)

        messages = [("system", system_prompt), ("user", user_prompt)]

        attempts = 4
        for attempt in range(attempts):
            try:
                resp = llm.invoke(messages)
                print(resp.content)
                print("\n## ğŸ“š Zdroje")
                for source in sources_info:
                    if source["url"]:
                        print(f"[{source['num']}] {source['title']} â€” {source['url']}")
                    else:
                        print(f"[{source['num']}] {source['title']}")
                break
            except Exception as e:
                emsg = str(e)
                if "Overloaded" in emsg or "529" in emsg:
                    wait = 2 ** attempt
                    print(f"WARN: Anthropic overloaded (529). Retry in {wait}sâ€¦", file=sys.stderr)
                    time.sleep(wait)
                    continue
                else:
                    print(f"WARN: Anthropic error: {e}. Falling back offline.", file=sys.stderr)
                    offline_reply(docs)
                    break
        else:
            print("WARN: Anthropic still overloaded after retries. Offline fallback.", file=sys.stderr)
            offline_reply(docs)

    except Exception as e:
        print(f"WARN: Anthropic client import/use failed: {e}. Offline fallback.", file=sys.stderr)
        offline_reply(docs)

elif OPENAI:
    try:
        from langchain_core.prompts import ChatPromptTemplate
        from langchain_openai import ChatOpenAI

        prompt = ChatPromptTemplate.from_messages([
            ("system", system_prompt),
            ("user", "{up}")
        ])
        llm = ChatOpenAI(model=os.environ.get("OPENAI_MODEL", "gpt-4o-mini"), temperature=0)
        resp = llm.invoke(prompt.format_messages(up=user_prompt))
        print(resp.content)
        print("\n## ğŸ“š Zdroje")
        for source in sources_info:
            if source["url"]:
                print(f"[{source['num']}] {source['title']} â€” {source['url']}")
            else:
                print(f"[{source['num']}] {source['title']}")

    except Exception as e:
        print(f"WARN: OpenAI error: {e}. Offline fallback.", file=sys.stderr)
        offline_reply(docs)

else:
    offline_reply(docs)
